{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "4"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. Regression discontinuity: banking recovery\n",
    "<p>After a debt has been legally declared \"uncollectable\" by a bank, the account is considered \"charged-off.\" But that doesn't mean the bank <strong><em>walks away</em></strong> from the debt. They still want to collect some of the money they are owed. The bank will score the account to assess the expected recovery amount, that is, the expected amount that the bank may be able to receive from the customer in the future. This amount is a function of the probability of the customer paying, the total debt, and other factors that impact the ability and willingness to pay.</p>\n",
    "<p>The bank has implemented different recovery strategies at different thresholds (\\$1000, \\$2000, etc.) where the greater the expected recovery amount, the more effort the bank puts into contacting the customer. For low recovery amounts (Level 0), the bank just adds the customer's contact information to their automatic dialer and emailing system. For higher recovery strategies, the bank incurs more costs as they leverage human resources in more efforts to obtain payments. Each additional level of recovery strategy requires an additional \\$50 per customer so that customers in the Recovery Strategy Level 1 cost the company \\$50 more than those in Level 0. Customers in Level 2 cost \\$50 more than those in Level 1, etc. </p>\n",
    "<p><strong>The big question</strong>: does the extra amount that is recovered at the higher strategy level exceed the extra \\$50 in costs? In other words, was there a jump (also called a \"discontinuity\") of more than \\$50 in the amount recovered at the higher strategy level? We'll find out in this notebook.</p>\n",
    "<p>![Regression discontinuity graph](https://assets.datacamp.com/production/project_504/img/Regression Discontinuity graph.png)</p>\n",
    "<p>First, we'll load the banking dataset and look at the first few rows of data. This lets us understand the dataset itself and begin thinking about how to analyze the data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dc": {
     "key": "4"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'bank_data.csv' does not exist: b'bank_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-131bbaa47405>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Read in dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bank_data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Print the first few rows of the DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\deeplearning\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'bank_data.csv' does not exist: b'bank_data.csv'"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in dataset\n",
    "df = pd.read_csv(\"datasets/bank_data.csv\")\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dc": {
     "key": "4"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%nose` not found.\n"
     ]
    }
   ],
   "source": [
    "%%nose\n",
    "\n",
    "first_value = _\n",
    "    \n",
    "def test_pandas_loaded():\n",
    "    assert pd.__name__ == 'pandas', \\\n",
    "        \"pandas should be imported as pd.\"\n",
    "\n",
    "def test_numpy_loaded():\n",
    "    assert np.__name__ == 'numpy', \\\n",
    "        \"numpy should be imported as np.\"\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "def test_df_correctly_loaded():\n",
    "    correct_df = pd.read_csv('datasets/bank_data.csv')\n",
    "    \n",
    "    assert correct_df.equals(df), \\\n",
    "        \"The variable df should contain the data in 'datasets/bank_data.csv'.\"\n",
    "        \n",
    "def test_head_output():\n",
    "    try:\n",
    "        assert \"2030\" in first_value.to_string()\n",
    "    except AttributeError:\n",
    "        assert False, \\\n",
    "            \"Please use df.head() as the last line of code in the cell to inspect the data, not the display() or print() functions.\"\n",
    "    except AssertionError:\n",
    "        assert False, \\\n",
    "            \"Hmm, the output of the cell is not what we expected. You should see 2030 in the first five rows of the df DataFrame.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "11"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. Graphical exploratory data analysis\n",
    "<p>The bank has implemented different recovery strategies at different thresholds (\\$1000, \\$2000, \\$3000 and \\$5000) where the greater the Expected Recovery Amount, the more effort the bank puts into contacting the customer. Zeroing in on the first transition (between Level 0 and Level 1) means we are focused on the population with Expected Recovery Amounts between \\$0 and \\$2000 where the transition between Levels occurred at \\$1000. We know that the customers in Level 1 (expected recovery amounts between \\$1001 and \\$2000) received more attention from the bank and, by definition, they had higher Expected Recovery Amounts than the customers in Level 0 (between \\$1 and \\$1000).</p>\n",
    "<p>Here's a quick summary of the Levels and thresholds again:</p>\n",
    "<ul>\n",
    "<li>Level 0: Expected recovery amounts &gt;\\$0 and &lt;=\\$1000</li>\n",
    "<li>Level 1: Expected recovery amounts &gt;\\$1000 and &lt;=\\$2000</li>\n",
    "<li>The threshold of \\$1000 separates Level 0 from Level 1</li>\n",
    "</ul>\n",
    "<p>A key question is whether there are other factors besides Expected Recovery Amount that also varied systematically across the \\$1000 threshold. For example, does the customer age show a jump (discontinuity) at the \\$1000 threshold or does that age vary smoothly? We can examine this by first making a scatter plot of the age as a function of Expected Recovery Amount for a small window of Expected Recovery Amount, \\$0 to \\$2000. This range covers Levels 0 and 1.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "11"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Scatter plot of Age vs. Expected Recovery Amount\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(x=df['expected_recovery_amount'], y=df['age'], c=\"g\", s=2)\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 60)\n",
    "plt.xlabel(\"Expected Recovery Amount\")\n",
    "plt.ylabel(\"Age\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "11"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "# no tests for plots\n",
    "\n",
    "# def test_nothing():\n",
    "#     assert True, \"Nothing to test.\"\n",
    "\n",
    "def test_matplotlib_loaded_2():\n",
    "    assert 'plt' in globals(), \\\n",
    "    'Did you import the pyplot module from matplotlib under the alias plt?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "18"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Statistical test:  age vs. expected recovery amount\n",
    "<p>We want to convince ourselves that variables such as age and sex are similar above and below the \\$1000 Expected Recovery Amount threshold. This is important because we want to be able to conclude that differences in the actual recovery amount are due to the higher Recovery Strategy and not due to some other difference like age or sex.</p>\n",
    "<p>The scatter plot of age versus Expected Recovery Amount did not show an obvious jump around \\$1000.  We will now do statistical analysis examining the average age of the customers just above and just below the threshold. We can start by exploring the range from \\$900 to \\$1100.</p>\n",
    "<p>For determining if there is a difference in the ages just above and just below the threshold, we will use the Kruskal-Wallis test, a statistical test that makes no distributional assumptions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "18"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import stats module\n",
    "from scipy import stats\n",
    "\n",
    "# Compute average age just below and above the threshold\n",
    "era_900_1100 = df.loc[(df['expected_recovery_amount']<1100) & \n",
    "                      (df['expected_recovery_amount']>=900)]\n",
    "by_recovery_strategy = era_900_1100.groupby(['recovery_strategy'])\n",
    "by_recovery_strategy['age'].describe().unstack()\n",
    "\n",
    "# Perform Kruskal-Wallis test \n",
    "print(df.recovery_strategy.unique()) # to see the recovery levels\n",
    "Level_0_age = era_900_1100.loc[df['recovery_strategy']==\"Level 0 Recovery\"]['age']\n",
    "Level_1_age = era_900_1100.loc[df['recovery_strategy']==\"Level 1 Recovery\"]['age']\n",
    "stats.kruskal(Level_0_age, Level_1_age) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "18"
    }
   },
   "source": [
    "The Kruskal-Wallis test is a non-parametric test meaning that it doesn't make any assumptions about the distributions. \n",
    "\n",
    "You can learn more about it [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kruskal.html) by reading the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "18"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_stats_loaded():\n",
    "    assert 'stats' in globals(), \\\n",
    "    'Did you import the stats module from scipy?'\n",
    "\n",
    "def test_level_0():\n",
    "    correct_Level_0_age_mean= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900) & \n",
    "                     (df['recovery_strategy']==\"Level 0 Recovery\")]['age'].mean()\n",
    "    Level_0_age_mean= Level_0_age.mean()\n",
    "    assert correct_Level_0_age_mean == Level_0_age_mean, \\\n",
    "        \"The mean age for Level_0_age appears to be incorrect. Did you correctly assign Level_0_age?\"\n",
    "\n",
    "def test_level_1():\n",
    "    correct_Level_1_age_mean= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900) & \n",
    "                     (df['recovery_strategy']==\"Level 1 Recovery\")]['age'].mean()\n",
    "    Level_1_age_mean= Level_1_age.mean()\n",
    "    assert correct_Level_1_age_mean == Level_1_age_mean, \\\n",
    "        \"The mean age for Level_1_age appears to be incorrect. Did you correctly assign Level_1_age?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "26"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Statistical test:  sex vs. expected recovery amount\n",
    "<p>We have seen that there is no major jump in the average customer age just above and just \n",
    "below the \\$1000 threshold by doing a statistical test as well as exploring it graphically with a scatter plot.  </p>\n",
    "<p>We want to also test that the percentage of customers that are male does not jump across the \\$1000 threshold. We can start by exploring the range of \\$900 to \\$1100 and later adjust this range.</p>\n",
    "<p>We can examine this question statistically by developing cross-tabs as well as doing chi-square tests of the percentage of customers that are male vs. female.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "26"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Number of customers in each category\n",
    "crosstab = pd.crosstab(df.loc[(df['expected_recovery_amount']<1100) & \n",
    "                              (df['expected_recovery_amount']>=900)]['recovery_strategy'], \n",
    "                       df['sex'])\n",
    "print(crosstab)\n",
    "\n",
    "# Chi-square test\n",
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(crosstab)\n",
    "print(\"P value : \", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "26"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_crosstab():\n",
    "    correct_crosstab = pd.crosstab(df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900)]['recovery_strategy'], df['sex'])\n",
    "    assert correct_crosstab.equals(crosstab), \\\n",
    "    \"The crosstab should select the expected_recovery_amount <1100 and >=900.\"\n",
    "\n",
    "def test_pval():\n",
    "    chi2_stat, correct_p_val, dof, ex = stats.chi2_contingency(crosstab)\n",
    "    assert correct_p_val==p_val, \\\n",
    "    \"The chi-square test function should use crosstab as the input variable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "33"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Exploratory graphical analysis: recovery amount\n",
    "<p>We are now reasonably confident that customers just above and just below the \\$1000 threshold are, on average, similar in their average age and the percentage that are male.  </p>\n",
    "<p>It is now time to focus on the key outcome of interest, the actual recovery amount.</p>\n",
    "<p>A first step in examining the relationship between the actual recovery amount and the expected recovery amount is to develop a scatter plot where we want to focus our attention at the range just below and just above the threshold. Specifically, we will develop a scatter plot of Expected Recovery Amount (Y) vs. Actual Recovery Amount (X) for Expected Recovery Amounts between \\$900 to \\$1100.  This range covers Levels 0 and 1.  A key question is whether or not we see a discontinuity (jump) around the \\$1000 threshold.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "33"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Scatter plot of Actual Recovery Amount vs. Expected Recovery Amount \n",
    "plt.scatter(x=df['expected_recovery_amount'], y=df['actual_recovery_amount'], c=\"g\", s=2)\n",
    "plt.xlim(900, 1100)\n",
    "plt.ylim(0, 2000)\n",
    "plt.xlabel(\"Expected Recovery Amount\")\n",
    "plt.ylabel(\"Actual Recovery Amount\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "33"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "# no tests for plots\n",
    "\n",
    "# def test_nothing():\n",
    "#     assert True, \"Nothing to test.\"\n",
    "\n",
    "def test_matplotlib_loaded_5():\n",
    "    assert 'plt' in globals(), \\\n",
    "    'Did you import the pyplot module from matplotlib under the alias plt?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "40"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Statistical analysis:  recovery amount\n",
    "<p>As we did with age, we can perform statistical tests to see if the actual recovery amount has a discontinuity above the \\$1000 threshold. We are going to do this for two different windows of the expected recovery amount \\$900 to \\$1100 and for a narrow range of \\$950 to \\$1050 to see if our results are consistent.</p>\n",
    "<p>Again, we will use the Kruskal-Wallis test.</p>\n",
    "<p>We will first compute the average actual recovery amount for those customers just below and just above the threshold using a range from \\$900 to \\$1100.  Then we will perform a Kruskal-Wallis test to see if the actual recovery amounts are different just above and just below the threshold.  Once we do that, we will repeat these steps for a smaller window of \\$950 to \\$1050.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "40"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Compute average actual recovery amount just below and above the threshold\n",
    "by_recovery_strategy['actual_recovery_amount'].describe().unstack()\n",
    "\n",
    "# Perform Kruskal-Wallis test\n",
    "Level_0_actual = era_900_1100.loc[df['recovery_strategy']=='Level 0 Recovery']['actual_recovery_amount']\n",
    "Level_1_actual = era_900_1100.loc[df['recovery_strategy']=='Level 1 Recovery']['actual_recovery_amount']\n",
    "print(stats.kruskal(Level_0_actual, Level_1_actual))\n",
    "\n",
    "# Repeat for a smaller range of $950 to $1050\n",
    "era_950_1050 = df.loc[(df['expected_recovery_amount']<1050) & \n",
    "                      (df['expected_recovery_amount']>=950)]\n",
    "Level_0_actual2 = era_950_1050.loc[df['recovery_strategy']=='Level 0 Recovery']['actual_recovery_amount']\n",
    "Level_1_actual2 = era_950_1050.loc[df['recovery_strategy']=='Level 1 Recovery']['actual_recovery_amount']\n",
    "print(stats.kruskal(Level_0_actual2, Level_1_actual2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "40"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_level_0():\n",
    "    correct_Level_0_actual_mean= df.loc[(df['expected_recovery_amount']<1050) & (df['expected_recovery_amount']>=950) & \n",
    "                     (df['recovery_strategy']==\"Level 0 Recovery\")]['actual_recovery_amount'].mean()\n",
    "    Level_0_actual_mean= Level_0_actual.mean()\n",
    "    assert correct_Level_0_actual_mean == Level_0_actual_mean, \\\n",
    "        \"The mean actual_recovery_amount for Level_0_actual appears to be incorrect. Did you correctly assign Level_0_actual?\"\n",
    "\n",
    "def test_level_1():\n",
    "    correct_Level_1_actual_mean= df.loc[(df['expected_recovery_amount']<1050) & (df['expected_recovery_amount']>=950) & \n",
    "                     (df['recovery_strategy']==\"Level 1 Recovery\")]['actual_recovery_amount'].mean()\n",
    "    Level_1_actual_mean= Level_1_actual.mean()\n",
    "    assert correct_Level_1_actual_mean == Level_1_actual_mean, \\\n",
    "        \"The mean actual_recovery_amount for Level_1_actual appears to be incorrect. Did you correctly assign Level_1_actual?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "48"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 7. Regression modeling: no threshold\n",
    "<p>We now want to take a regression-based approach to estimate the program impact at the \\$1000 threshold using data that is just above and below the threshold. </p>\n",
    "<p>We will build two models. The first model does not have a threshold while the second will include a threshold.</p>\n",
    "<p>The first model predicts the actual recovery amount (dependent variable) as a function of the expected recovery amount (independent variable). We expect that there will be a strong positive relationship between these two variables.  </p>\n",
    "<p>We will examine the adjusted R-squared to see the percent of variance explained by the model.  In this model, we are not representing the threshold but simply seeing how the variable used for assigning the customers (expected recovery amount) relates to the outcome variable (actual recovery amount).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "48"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Define X and y\n",
    "X = era_900_1100['expected_recovery_amount']\n",
    "y = era_900_1100['actual_recovery_amount']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Build linear regression model\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print out the model summary statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "48"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_x():\n",
    "    correct_x= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900)]['expected_recovery_amount']\n",
    "    correct_x = sm.add_constant(correct_x)\n",
    "    assert correct_x['expected_recovery_amount'].mean() == X['expected_recovery_amount'].mean(), \\\n",
    "        \"The mean expected_recovery_amount for X appears incorrect. Check your assignment of X.  It should include expected_recovery_amount and indicator_1000 when the expected_recovery_amount is <1100 and >=900.\"\n",
    "def test_y():\n",
    "    correct_y= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900)]['actual_recovery_amount']\n",
    "    assert correct_y.mean() == y.mean(), \\\n",
    "        \"The mean actual_recovery_amount for y appears incorrect. Check your assignment of y. It should include the actual_recovery_amount when the expected_recovery_amount is <1100 and >=900.\"\n",
    "        \n",
    "# def test_df_correctly_loaded():\n",
    "#     correct_model = sm.OLS(y,x).fit()\n",
    "#     assert correct_model.params[1] == model.params[1], \\\n",
    "#         \"Check your assignment of model. It should be equal to sm.OLS(y,X).fit().\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "55"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 8. Regression modeling: adding true threshold\n",
    "<p>From the first model, we see that the expected recovery amount's regression coefficient is statistically significant. </p>\n",
    "<p>The second model adds an indicator of the true threshold to the model (in this case at \\$1000).  </p>\n",
    "<p>We will create an indicator variable (either a 0 or a 1) that represents whether or not the expected recovery amount was greater than \\$1000. When we add the true threshold to the model, the regression coefficient for the true threshold represents the additional amount recovered due to the higher recovery strategy.  That is to say, the regression coefficient for the true threshold measures the size of the discontinuity for customers just above and just below the threshold.</p>\n",
    "<p>If the higher recovery strategy helped recovery more money, then the regression coefficient of the true threshold will be greater than zero.  If the higher recovery strategy did not help recovery more money, then the regression coefficient will not be statistically significant.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "55"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Create indicator (0 or 1) for expected recovery amount >= $1000\n",
    "df['indicator_1000'] = np.where(df['expected_recovery_amount']<1000, 0, 1)\n",
    "era_900_1100 = df.loc[(df['expected_recovery_amount']<1100) & \n",
    "                      (df['expected_recovery_amount']>=900)]\n",
    "\n",
    "# Define X and y\n",
    "X = era_900_1100[['expected_recovery_amount', 'indicator_1000']]\n",
    "y = era_900_1100['actual_recovery_amount']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Build linear regression model\n",
    "model2 = sm.OLS(y,X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "55"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_x():\n",
    "    correct_x= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900),\n",
    "           ['expected_recovery_amount','indicator_1000']]\n",
    "    correct_x = sm.add_constant(correct_x)\n",
    "    assert correct_x['expected_recovery_amount'].mean() == X['expected_recovery_amount'].mean(), \\\n",
    "        \"The mean expected_recovery_amount for X appears incorrect. Check your assignment of X.  It should include expected_recovery_amount and indicator_1000 when the expected_recovery_amount is <1100 and >=900.\"\n",
    "def test_y():\n",
    "    correct_y= df.loc[(df['expected_recovery_amount']<1100) & (df['expected_recovery_amount']>=900)]['actual_recovery_amount']\n",
    "    assert correct_y.mean() == y.mean(), \\\n",
    "        \"The mean actual_recovery_amount for y appears incorrect. Check your assignment of y. It should include the actual_recovery_amount when the expected_recovery_amount is <1100 and >=900.\"\n",
    "        \n",
    "# def test_df_correctly_loaded():\n",
    "#     correct_model = sm.OLS(y,X).fit()\n",
    "#     assert correct_model.params[1] == model.params[1], \\\n",
    "#         \"Check your assignment of model. It should be equal to sm.OLS(y,X).fit().\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "62"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 9. Regression modeling: adjusting the window\n",
    "<p>The regression coefficient for the true threshold was statistically significant with an estimated impact of around \\$278.  This is much larger than the \\$50 per customer needed to run this higher recovery strategy. </p>\n",
    "<p>Before showing this to our manager, we want to convince ourselves that this result wasn't due to choosing an expected recovery amount window of \\$900 to \\$1100. Let's repeat this analysis for the window from \\$950 to \\$1050 to see if we get similar results.</p>\n",
    "<p>The answer? Whether we use a wide (\\$900 to \\$1100) or narrower window (\\$950 to \\$1050), the incremental recovery amount at the higher recovery strategy is much greater than the \\$50 per customer it costs for the higher recovery strategy.  So we conclude that the higher recovery strategy is worth the extra cost of \\$50 per customer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "62"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Redefine era_950_1050 so the indicator variable is included\n",
    "era_950_1050 = df.loc[(df['expected_recovery_amount']<1050) & \n",
    "                      (df['expected_recovery_amount']>=950)]\n",
    "\n",
    "# Define X and y \n",
    "X = era_950_1050[['expected_recovery_amount','indicator_1000']]\n",
    "y = era_950_1050['actual_recovery_amount']\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Build linear regression model\n",
    "model = sm.OLS(y,X).fit()\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "dc": {
     "key": "62"
    },
    "hide": true,
    "tags": [
     "tests"
    ]
   },
   "outputs": [],
   "source": [
    "%%nose\n",
    "\n",
    "def test_x():\n",
    "    correct_x= df.loc[(df['expected_recovery_amount']<1050) & (df['expected_recovery_amount']>=950),['expected_recovery_amount','indicator_1000']]\n",
    "    correct_x = sm.add_constant(correct_x)\n",
    "    assert correct_x['expected_recovery_amount'].mean() == X['expected_recovery_amount'].mean(), \\\n",
    "        \"The mean expected_recovery_amount for X appears incorrect. Check your assignment of X.  It should include expected_recovery_amount and indicator_1000 when the expected_recovery_amount is <1050 and >=950.\"\n",
    "def test_y():\n",
    "    correct_y= df.loc[(df['expected_recovery_amount']<1050) & (df['expected_recovery_amount']>=950)]['actual_recovery_amount']\n",
    "    assert correct_y.mean() == y.mean(), \\\n",
    "        \"The mean actual_recovery_amount for y appears incorrect. Check your assignment of y. It should include the actual_recovery_amount when the expected_recovery_amount is <1050 and >=950.\"\n",
    "        \n",
    "# def test_df_correctly_loaded():\n",
    "#     correct_model = sm.OLS(y,X).fit()\n",
    "#     assert correct_model.params[1] == model.params[1], \\\n",
    "#         \"Check your assignment of model.  It should be equal to sm.OLS(y,X).fit().\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
